{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f1626e3-11b4-49fe-b44c-90225ff9eb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding /Users/bensoorajmohan/Development/ai-playground/bensooraj-pytorch-cifar10-play/src to system paths\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_module_path = os.path.abspath(os.path.join('../'))\n",
    "if project_module_path not in sys.path:\n",
    "    print(f'Adding {project_module_path} to system paths')\n",
    "    sys.path.append(project_module_path)\n",
    "\n",
    "# %env AWS_PROFILE=development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d38aff-b896-44c2-884a-bd3462d887cc",
   "metadata": {},
   "source": [
    "# Base Model v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab29b41-8b3a-4e84-8853-af97cc385f6e",
   "metadata": {},
   "source": [
    "## Target\n",
    "- Basic setup: Loading data, train and test loops\n",
    "- Basic model with regularization to prevent overfitting and improve generalization,\n",
    "    - Batch-normalisation to reduce the risk of memorizing noise in the training data\n",
    "    - Dropout to perform better on new and unseen data.\n",
    "- Global Average Pooling instead of a fully connected layer at the end\n",
    "## Result\n",
    "- Parameters: 24,986\n",
    "- Accuracy:\n",
    "| Accuracy | Best | Final |\n",
    "| --- | --- | --- |\n",
    "| Train | 99.77 | 99.77\n",
    "| Test | 99.81 | 99.40\n",
    "## Analysis\n",
    "- Model is moderately heavy\n",
    "- Overfitting (train acc > test acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e24f0-a01c-4832-a15f-babf45c07171",
   "metadata": {},
   "source": [
    "## Import all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58cb3d88-a205-4a4d-a420-46e718590398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.5.1)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "!pip install torchsummary\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b33c8053-c5a5-4a8f-8525-d710444c3f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:logging configured\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "logging.info(\"logging configured\")  # calling the root logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bee8caf-ab88-4cb2-8fcb-6e188455ba29",
   "metadata": {},
   "source": [
    "## Configure device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbf2114d-d567-41ca-9255-5308465af4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "use_mps = torch.backends.mps.is_available()\n",
    "\n",
    "device: torch.device = None\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "elif use_mps:\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "assert device is not None, \"device must not be None\"\n",
    "assert isinstance(device, torch.device), \"device must be an instance of torch.device\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2944927-0043-44e8-9b9a-8b3ee56824ef",
   "metadata": {},
   "source": [
    "## Download the dataset and configure loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6203d50a-5f69-4c9a-a838-01df0e231b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train = datasets.CIFAR10('../../data', train=True, download=True, transform=train_transforms)\n",
    "test = datasets.CIFAR10('../../data', train=False, download=True, transform=test_transforms)\n",
    "\n",
    "dataloader_args = dict(shuffle=True, batch_size=BATCH_SIZE, num_workers=2, pin_memory=True) if (use_cuda or use_mps) else dict(shuffle=True, batch_size=64)\n",
    "\n",
    "# train dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
    "\n",
    "# test dataloader\n",
    "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4c562c-6d13-45b5-8ee8-53f7924393a0",
   "metadata": {},
   "source": [
    "## Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c690c38-6891-43bc-aedc-214af5aed925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             128\n",
      "              ReLU-2           [-1, 32, 28, 28]               0\n",
      "            Conv2d-3           [-1, 32, 26, 26]           9,248\n",
      "              ReLU-4           [-1, 32, 26, 26]               0\n",
      "            Conv2d-5           [-1, 64, 26, 26]           2,112\n",
      "              ReLU-6           [-1, 64, 26, 26]               0\n",
      "            Conv2d-7          [-1, 256, 26, 26]          16,640\n",
      "              ReLU-8          [-1, 256, 26, 26]               0\n",
      "            Conv2d-9          [-1, 256, 26, 26]           2,560\n",
      "             ReLU-10          [-1, 256, 26, 26]               0\n",
      "           Conv2d-11          [-1, 128, 26, 26]          32,896\n",
      "             ReLU-12          [-1, 128, 26, 26]               0\n",
      "           Conv2d-13           [-1, 64, 26, 26]           8,256\n",
      "             ReLU-14           [-1, 64, 26, 26]               0\n",
      "           Conv2d-15           [-1, 64, 22, 22]          36,928\n",
      "             ReLU-16           [-1, 64, 22, 22]               0\n",
      "           Conv2d-17          [-1, 128, 22, 22]           8,320\n",
      "             ReLU-18          [-1, 128, 22, 22]               0\n",
      "           Conv2d-19           [-1, 64, 22, 22]           8,256\n",
      "             ReLU-20           [-1, 64, 22, 22]               0\n",
      "           Conv2d-21           [-1, 64, 20, 20]          36,928\n",
      "             ReLU-22           [-1, 64, 20, 20]               0\n",
      "           Conv2d-23          [-1, 128, 20, 20]           8,320\n",
      "             ReLU-24          [-1, 128, 20, 20]               0\n",
      "        AvgPool2d-25          [-1, 128, 20, 20]               0\n",
      "================================================================\n",
      "Total params: 170,592\n",
      "Trainable params: 170,592\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 12.09\n",
      "Params size (MB): 0.65\n",
      "Estimated Total Size (MB): 12.75\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from models import ModelV1\n",
    "summary(ModelV1(), input_size=(3, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6812aa9-514c-4898-a345-f2da2b2d0c3b",
   "metadata": {},
   "source": [
    "## Train and evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46205ee9-cc3d-4785-a240-acbf2bfb8b52",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e3bcf4e-7383-4aae-8c1c-dc0d11c5c9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tConfig: batch_size=128 epochs=15 lr=0.01 momentum=0.9 seed=1 log_dir='logs/mnist' summaryWriter=<torch.utils.tensorboard.writer.SummaryWriter object at 0x1045e49d0>\n"
     ]
    }
   ],
   "source": [
    "from pytorch_mnist_play import Config, Trainer\n",
    "\n",
    "summaryWriter=SummaryWriter(\"../../logs/mnist\")\n",
    "tConfig = Config(\n",
    "    summaryWriter=summaryWriter,\n",
    "    epochs=15\n",
    ")\n",
    "print(f\"tConfig: {tConfig}\")\n",
    "\n",
    "modelV1 = ModelV1().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53da66cb-91c9-4672-8ccd-a083bd85b51e",
   "metadata": {},
   "source": [
    "### Start the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6f5e13-bf71-49cf-99bd-3e5895abceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(tConfig)\n",
    "trainer.fit(modelV1, device, train_loader, test_loader, modelV1.name())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
