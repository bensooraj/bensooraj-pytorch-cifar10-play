{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f1626e3-11b4-49fe-b44c-90225ff9eb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_module_path = os.path.abspath(os.path.join('../'))\n",
    "if project_module_path not in sys.path:\n",
    "    print(f'Adding {project_module_path} to system paths')\n",
    "    sys.path.append(project_module_path)\n",
    "\n",
    "# %env AWS_PROFILE=development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d38aff-b896-44c2-884a-bd3462d887cc",
   "metadata": {},
   "source": [
    "# Base Model v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab29b41-8b3a-4e84-8853-af97cc385f6e",
   "metadata": {},
   "source": [
    "## Target\n",
    "- Basic setup: Loading data, train and test loops\n",
    "- Basic model with regularization to prevent overfitting and improve generalization,\n",
    "    - Batch-normalisation to reduce the risk of memorizing noise in the training data\n",
    "    - Dropout to perform better on new and unseen data.\n",
    "- Global Average Pooling instead of a fully connected layer at the end\n",
    "## Result\n",
    "- Parameters: 24,986\n",
    "- Accuracy:\n",
    "| Accuracy | Best | Final |\n",
    "| --- | --- | --- |\n",
    "| Train | 99.77 | 99.77\n",
    "| Test | 99.81 | 99.40\n",
    "## Analysis\n",
    "- Model is moderately heavy\n",
    "- Overfitting (train acc > test acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e24f0-a01c-4832-a15f-babf45c07171",
   "metadata": {},
   "source": [
    "## Import all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58cb3d88-a205-4a4d-a420-46e718590398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# !pip install albumentations==2.0.8\n",
    "# !pip install torchsummary\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b33c8053-c5a5-4a8f-8525-d710444c3f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:logging configured\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "logging.info(\"logging configured\")  # calling the root logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bee8caf-ab88-4cb2-8fcb-6e188455ba29",
   "metadata": {},
   "source": [
    "## Configure device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbf2114d-d567-41ca-9255-5308465af4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "use_mps = torch.backends.mps.is_available()\n",
    "\n",
    "device: torch.device = None\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "elif use_mps:\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "assert device is not None, \"device must not be None\"\n",
    "assert isinstance(device, torch.device), \"device must be an instance of torch.device\"\n",
    "\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2944927-0043-44e8-9b9a-8b3ee56824ef",
   "metadata": {},
   "source": [
    "## Download the dataset and configure loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6203d50a-5f69-4c9a-a838-01df0e231b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:13<00:00, 13.0MB/s] \n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "from data import train_transforms, test_transforms\n",
    "\n",
    "torch.manual_seed(1)\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Transforms\n",
    "# train_transforms = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.1307,), (0.3081,))\n",
    "# ])\n",
    "# test_transforms = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.1307,), (0.3081,))\n",
    "# ])\n",
    "\n",
    "train = datasets.CIFAR10('../../data', train=True, download=True, transform=train_transforms)\n",
    "test = datasets.CIFAR10('../../data', train=False, download=True, transform=test_transforms)\n",
    "\n",
    "dataloader_args = dict(shuffle=True, batch_size=BATCH_SIZE, num_workers=2, pin_memory=True) if (use_cuda or use_mps) else dict(shuffle=True, batch_size=64)\n",
    "\n",
    "# train dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
    "\n",
    "# test dataloader\n",
    "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4c562c-6d13-45b5-8ee8-53f7924393a0",
   "metadata": {},
   "source": [
    "## Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c690c38-6891-43bc-aedc-214af5aed925",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelV1\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModelV1\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m28\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bensooraj-pytorch-cifar10-play/.venv/lib/python3.12/site-packages/torchsummary/torchsummary.py:72\u001b[39m, in \u001b[36msummary\u001b[39m\u001b[34m(model, input_size, batch_size, device)\u001b[39m\n\u001b[32m     68\u001b[39m model.apply(register_hook)\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bensooraj-pytorch-cifar10-play/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bensooraj-pytorch-cifar10-play/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bensooraj-pytorch-cifar10-play/src/models/model_v1.py:94\u001b[39m, in \u001b[36mModelV1.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblock01\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.block02(x)\n\u001b[32m     96\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.block03(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bensooraj-pytorch-cifar10-play/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bensooraj-pytorch-cifar10-play/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bensooraj-pytorch-cifar10-play/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bensooraj-pytorch-cifar10-play/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bensooraj-pytorch-cifar10-play/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1879\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1876\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1878\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1879\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1880\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1881\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1882\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1883\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1884\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bensooraj-pytorch-cifar10-play/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1827\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1824\u001b[39m     bw_hook = BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[32m   1825\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1827\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1828\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n\u001b[32m   1829\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   1830\u001b[39m         *_global_forward_hooks.items(),\n\u001b[32m   1831\u001b[39m         *\u001b[38;5;28mself\u001b[39m._forward_hooks.items(),\n\u001b[32m   1832\u001b[39m     ):\n\u001b[32m   1833\u001b[39m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bensooraj-pytorch-cifar10-play/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bensooraj-pytorch-cifar10-play/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "from models import ModelV1\n",
    "summary(ModelV1(), input_size=(3, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6812aa9-514c-4898-a345-f2da2b2d0c3b",
   "metadata": {},
   "source": [
    "## Train and evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46205ee9-cc3d-4785-a240-acbf2bfb8b52",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e3bcf4e-7383-4aae-8c1c-dc0d11c5c9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tConfig: batch_size=128 epochs=100 lr=0.01 enable_lr_scheduler=True momentum=0.9 seed=1 log_dir='logs/mnist' summaryWriter=<torch.utils.tensorboard.writer.SummaryWriter object at 0x7b203232e810>\n"
     ]
    }
   ],
   "source": [
    "from pytorch_play import Config, Trainer\n",
    "\n",
    "summaryWriter=SummaryWriter(\"../../logs/cifar10\")\n",
    "tConfig = Config(\n",
    "    summaryWriter=summaryWriter,\n",
    "    enable_lr_scheduler=True,\n",
    "    epochs=100\n",
    ")\n",
    "print(f\"tConfig: {tConfig}\")\n",
    "\n",
    "modelV1 = ModelV1().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53da66cb-91c9-4672-8ccd-a083bd85b51e",
   "metadata": {},
   "source": [
    "### Start the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e6f5e13-bf71-49cf-99bd-3e5895abceb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 391/391 [00:24<00:00, 15.69it/s, batch_id=390, loss=1.5951]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 01 - Accuracy: 17015/50000 (34.03%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 01 - Loss: 1.5062, Accuracy: 4577/10000 (45.77%)\n",
      "Epoch 2: 100%|██████████| 391/391 [00:23<00:00, 16.45it/s, batch_id=390, loss=1.5107]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 02 - Accuracy: 22788/50000 (45.58%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 02 - Loss: 1.2721, Accuracy: 5527/10000 (55.27%)\n",
      "Epoch 3: 100%|██████████| 391/391 [00:23<00:00, 16.41it/s, batch_id=390, loss=1.3191]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 03 - Accuracy: 25589/50000 (51.18%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 03 - Loss: 1.2201, Accuracy: 5633/10000 (56.33%)\n",
      "Epoch 4: 100%|██████████| 391/391 [00:23<00:00, 16.39it/s, batch_id=390, loss=1.2822]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 04 - Accuracy: 27398/50000 (54.80%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 04 - Loss: 1.0473, Accuracy: 6320/10000 (63.20%)\n",
      "Epoch 5: 100%|██████████| 391/391 [00:23<00:00, 16.40it/s, batch_id=390, loss=0.9517]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 05 - Accuracy: 28691/50000 (57.38%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 05 - Loss: 0.9525, Accuracy: 6676/10000 (66.76%)\n",
      "Epoch 6: 100%|██████████| 391/391 [00:23<00:00, 16.40it/s, batch_id=390, loss=1.1858]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 06 - Accuracy: 29794/50000 (59.59%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 06 - Loss: 0.9375, Accuracy: 6687/10000 (66.87%)\n",
      "Epoch 7: 100%|██████████| 391/391 [00:23<00:00, 16.41it/s, batch_id=390, loss=1.0997]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 07 - Accuracy: 31809/50000 (63.62%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 07 - Loss: 0.8085, Accuracy: 7218/10000 (72.18%)\n",
      "Epoch 8: 100%|██████████| 391/391 [00:23<00:00, 16.40it/s, batch_id=390, loss=1.2289]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 08 - Accuracy: 32370/50000 (64.74%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 08 - Loss: 0.7946, Accuracy: 7272/10000 (72.72%)\n",
      "Epoch 9: 100%|██████████| 391/391 [00:23<00:00, 16.40it/s, batch_id=390, loss=1.0182]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 09 - Accuracy: 32514/50000 (65.03%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 09 - Loss: 0.7783, Accuracy: 7347/10000 (73.47%)\n",
      "Epoch 10: 100%|██████████| 391/391 [00:23<00:00, 16.37it/s, batch_id=390, loss=0.9629]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 10 - Accuracy: 32840/50000 (65.68%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 10 - Loss: 0.7766, Accuracy: 7370/10000 (73.70%)\n",
      "Epoch 11: 100%|██████████| 391/391 [00:23<00:00, 16.40it/s, batch_id=390, loss=0.9530]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 11 - Accuracy: 32821/50000 (65.64%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 11 - Loss: 0.7652, Accuracy: 7409/10000 (74.09%)\n",
      "Epoch 12: 100%|██████████| 391/391 [00:23<00:00, 16.37it/s, batch_id=390, loss=1.1111]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 12 - Accuracy: 32932/50000 (65.86%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 12 - Loss: 0.7587, Accuracy: 7425/10000 (74.25%)\n",
      "Epoch 13: 100%|██████████| 391/391 [00:23<00:00, 16.38it/s, batch_id=390, loss=1.0188]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 13 - Accuracy: 33438/50000 (66.88%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 13 - Loss: 0.7544, Accuracy: 7422/10000 (74.22%)\n",
      "Epoch 14: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=0.9069]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 14 - Accuracy: 33363/50000 (66.73%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 14 - Loss: 0.7481, Accuracy: 7438/10000 (74.38%)\n",
      "Epoch 15: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=0.7709]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 15 - Accuracy: 33445/50000 (66.89%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 15 - Loss: 0.7500, Accuracy: 7441/10000 (74.41%)\n",
      "Epoch 16: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=0.8285]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 16 - Accuracy: 33405/50000 (66.81%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 16 - Loss: 0.7471, Accuracy: 7458/10000 (74.58%)\n",
      "Epoch 17: 100%|██████████| 391/391 [00:23<00:00, 16.38it/s, batch_id=390, loss=0.9537]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 17 - Accuracy: 33655/50000 (67.31%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 17 - Loss: 0.7462, Accuracy: 7451/10000 (74.51%)\n",
      "Epoch 18: 100%|██████████| 391/391 [00:23<00:00, 16.38it/s, batch_id=390, loss=0.7726]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 18 - Accuracy: 33652/50000 (67.30%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 18 - Loss: 0.7451, Accuracy: 7465/10000 (74.65%)\n",
      "Epoch 19: 100%|██████████| 391/391 [00:23<00:00, 16.38it/s, batch_id=390, loss=1.0873]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 19 - Accuracy: 33583/50000 (67.17%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 19 - Loss: 0.7431, Accuracy: 7462/10000 (74.62%)\n",
      "Epoch 20: 100%|██████████| 391/391 [00:23<00:00, 16.37it/s, batch_id=390, loss=0.8728]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 20 - Accuracy: 33420/50000 (66.84%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 20 - Loss: 0.7421, Accuracy: 7479/10000 (74.79%)\n",
      "Epoch 21: 100%|██████████| 391/391 [00:23<00:00, 16.38it/s, batch_id=390, loss=0.9316]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 21 - Accuracy: 33469/50000 (66.94%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 21 - Loss: 0.7443, Accuracy: 7466/10000 (74.66%)\n",
      "Epoch 22: 100%|██████████| 391/391 [00:23<00:00, 16.37it/s, batch_id=390, loss=1.1230]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 22 - Accuracy: 33575/50000 (67.15%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 22 - Loss: 0.7451, Accuracy: 7456/10000 (74.56%)\n",
      "Epoch 23: 100%|██████████| 391/391 [00:23<00:00, 16.37it/s, batch_id=390, loss=0.8564]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 23 - Accuracy: 33532/50000 (67.06%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 23 - Loss: 0.7452, Accuracy: 7454/10000 (74.54%)\n",
      "Epoch 24: 100%|██████████| 391/391 [00:23<00:00, 16.39it/s, batch_id=390, loss=0.8651]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 24 - Accuracy: 33537/50000 (67.07%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 24 - Loss: 0.7432, Accuracy: 7471/10000 (74.71%)\n",
      "Epoch 25: 100%|██████████| 391/391 [00:23<00:00, 16.40it/s, batch_id=390, loss=0.8576]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 25 - Accuracy: 33579/50000 (67.16%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 25 - Loss: 0.7439, Accuracy: 7466/10000 (74.66%)\n",
      "Epoch 26: 100%|██████████| 391/391 [00:23<00:00, 16.40it/s, batch_id=390, loss=1.0992]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 26 - Accuracy: 33609/50000 (67.22%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 26 - Loss: 0.7464, Accuracy: 7457/10000 (74.57%)\n",
      "Epoch 27: 100%|██████████| 391/391 [00:23<00:00, 16.39it/s, batch_id=390, loss=0.8906]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 27 - Accuracy: 33562/50000 (67.12%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 27 - Loss: 0.7452, Accuracy: 7458/10000 (74.58%)\n",
      "Epoch 28: 100%|██████████| 391/391 [00:23<00:00, 16.39it/s, batch_id=390, loss=0.9468]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 28 - Accuracy: 33608/50000 (67.22%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 28 - Loss: 0.7447, Accuracy: 7460/10000 (74.60%)\n",
      "Epoch 29: 100%|██████████| 391/391 [00:23<00:00, 16.39it/s, batch_id=390, loss=1.1712]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 29 - Accuracy: 33603/50000 (67.21%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 29 - Loss: 0.7445, Accuracy: 7465/10000 (74.65%)\n",
      "Epoch 30: 100%|██████████| 391/391 [00:23<00:00, 16.37it/s, batch_id=390, loss=0.8458]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 30 - Accuracy: 33614/50000 (67.23%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 30 - Loss: 0.7434, Accuracy: 7459/10000 (74.59%)\n",
      "Epoch 31: 100%|██████████| 391/391 [00:23<00:00, 16.40it/s, batch_id=390, loss=1.0562]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 31 - Accuracy: 33572/50000 (67.14%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 31 - Loss: 0.7457, Accuracy: 7455/10000 (74.55%)\n",
      "Epoch 32: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=0.7725]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 32 - Accuracy: 33627/50000 (67.25%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 32 - Loss: 0.7480, Accuracy: 7449/10000 (74.49%)\n",
      "Epoch 33: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=0.9715]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 33 - Accuracy: 33600/50000 (67.20%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 33 - Loss: 0.7434, Accuracy: 7465/10000 (74.65%)\n",
      "Epoch 34: 100%|██████████| 391/391 [00:23<00:00, 16.38it/s, batch_id=390, loss=1.1058]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 34 - Accuracy: 33622/50000 (67.24%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 34 - Loss: 0.7455, Accuracy: 7451/10000 (74.51%)\n",
      "Epoch 35: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=1.0308]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 35 - Accuracy: 33572/50000 (67.14%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 35 - Loss: 0.7430, Accuracy: 7464/10000 (74.64%)\n",
      "Epoch 36: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=1.0781]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 36 - Accuracy: 33533/50000 (67.07%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 36 - Loss: 0.7471, Accuracy: 7452/10000 (74.52%)\n",
      "Epoch 37: 100%|██████████| 391/391 [00:23<00:00, 16.39it/s, batch_id=390, loss=0.9877]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 37 - Accuracy: 33554/50000 (67.11%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 37 - Loss: 0.7428, Accuracy: 7476/10000 (74.76%)\n",
      "Epoch 38: 100%|██████████| 391/391 [00:23<00:00, 16.38it/s, batch_id=390, loss=0.9886]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 38 - Accuracy: 33562/50000 (67.12%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 38 - Loss: 0.7435, Accuracy: 7466/10000 (74.66%)\n",
      "Epoch 39: 100%|██████████| 391/391 [00:23<00:00, 16.37it/s, batch_id=390, loss=0.9987]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 39 - Accuracy: 33466/50000 (66.93%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 39 - Loss: 0.7462, Accuracy: 7450/10000 (74.50%)\n",
      "Epoch 40: 100%|██████████| 391/391 [00:23<00:00, 16.35it/s, batch_id=390, loss=0.9885]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 40 - Accuracy: 33710/50000 (67.42%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 40 - Loss: 0.7439, Accuracy: 7464/10000 (74.64%)\n",
      "Epoch 41: 100%|██████████| 391/391 [00:23<00:00, 16.35it/s, batch_id=390, loss=0.9479]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 41 - Accuracy: 33631/50000 (67.26%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 41 - Loss: 0.7446, Accuracy: 7474/10000 (74.74%)\n",
      "Epoch 42: 100%|██████████| 391/391 [00:23<00:00, 16.37it/s, batch_id=390, loss=1.0625]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 42 - Accuracy: 33568/50000 (67.14%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 42 - Loss: 0.7446, Accuracy: 7452/10000 (74.52%)\n",
      "Epoch 43: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=1.0234]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 43 - Accuracy: 33715/50000 (67.43%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 43 - Loss: 0.7448, Accuracy: 7462/10000 (74.62%)\n",
      "Epoch 44: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=1.0387]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 44 - Accuracy: 33595/50000 (67.19%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 44 - Loss: 0.7454, Accuracy: 7466/10000 (74.66%)\n",
      "Epoch 45: 100%|██████████| 391/391 [00:23<00:00, 16.39it/s, batch_id=390, loss=0.8443]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 45 - Accuracy: 33729/50000 (67.46%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 45 - Loss: 0.7433, Accuracy: 7473/10000 (74.73%)\n",
      "Epoch 46: 100%|██████████| 391/391 [00:23<00:00, 16.37it/s, batch_id=390, loss=0.8412]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 46 - Accuracy: 33614/50000 (67.23%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 46 - Loss: 0.7426, Accuracy: 7466/10000 (74.66%)\n",
      "Epoch 47: 100%|██████████| 391/391 [00:23<00:00, 16.38it/s, batch_id=390, loss=0.9361]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 47 - Accuracy: 33558/50000 (67.12%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 47 - Loss: 0.7452, Accuracy: 7470/10000 (74.70%)\n",
      "Epoch 48: 100%|██████████| 391/391 [00:23<00:00, 16.40it/s, batch_id=390, loss=0.7746]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 48 - Accuracy: 33568/50000 (67.14%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 48 - Loss: 0.7448, Accuracy: 7458/10000 (74.58%)\n",
      "Epoch 49: 100%|██████████| 391/391 [00:23<00:00, 16.38it/s, batch_id=390, loss=1.0575]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 49 - Accuracy: 33613/50000 (67.23%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 49 - Loss: 0.7420, Accuracy: 7474/10000 (74.74%)\n",
      "Epoch 50: 100%|██████████| 391/391 [00:23<00:00, 16.38it/s, batch_id=390, loss=0.9416]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 50 - Accuracy: 33575/50000 (67.15%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 50 - Loss: 0.7454, Accuracy: 7467/10000 (74.67%)\n",
      "Epoch 51: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=0.9314]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 51 - Accuracy: 33591/50000 (67.18%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 51 - Loss: 0.7437, Accuracy: 7454/10000 (74.54%)\n",
      "Epoch 52: 100%|██████████| 391/391 [00:23<00:00, 16.37it/s, batch_id=390, loss=1.2753]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 52 - Accuracy: 33572/50000 (67.14%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 52 - Loss: 0.7446, Accuracy: 7473/10000 (74.73%)\n",
      "Epoch 53: 100%|██████████| 391/391 [00:23<00:00, 16.39it/s, batch_id=390, loss=1.0754]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 53 - Accuracy: 33510/50000 (67.02%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 53 - Loss: 0.7411, Accuracy: 7461/10000 (74.61%)\n",
      "Epoch 54: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=0.8763]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 54 - Accuracy: 33634/50000 (67.27%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 54 - Loss: 0.7464, Accuracy: 7466/10000 (74.66%)\n",
      "Epoch 55: 100%|██████████| 391/391 [00:23<00:00, 16.35it/s, batch_id=390, loss=1.0350]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 55 - Accuracy: 33735/50000 (67.47%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 55 - Loss: 0.7437, Accuracy: 7462/10000 (74.62%)\n",
      "Epoch 56: 100%|██████████| 391/391 [00:23<00:00, 16.35it/s, batch_id=390, loss=0.8540]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 56 - Accuracy: 33601/50000 (67.20%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 56 - Loss: 0.7432, Accuracy: 7472/10000 (74.72%)\n",
      "Epoch 57: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=1.0308]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 57 - Accuracy: 33523/50000 (67.05%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 57 - Loss: 0.7460, Accuracy: 7467/10000 (74.67%)\n",
      "Epoch 58: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=1.0429]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 58 - Accuracy: 33563/50000 (67.13%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 58 - Loss: 0.7439, Accuracy: 7462/10000 (74.62%)\n",
      "Epoch 59: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=0.9380]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 59 - Accuracy: 33624/50000 (67.25%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 59 - Loss: 0.7442, Accuracy: 7465/10000 (74.65%)\n",
      "Epoch 60: 100%|██████████| 391/391 [00:23<00:00, 16.35it/s, batch_id=390, loss=0.9691]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 60 - Accuracy: 33481/50000 (66.96%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 60 - Loss: 0.7431, Accuracy: 7475/10000 (74.75%)\n",
      "Epoch 61: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=0.8123]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 61 - Accuracy: 33482/50000 (66.96%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 61 - Loss: 0.7463, Accuracy: 7460/10000 (74.60%)\n",
      "Epoch 62: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=0.8391]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 62 - Accuracy: 33655/50000 (67.31%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 62 - Loss: 0.7431, Accuracy: 7461/10000 (74.61%)\n",
      "Epoch 63: 100%|██████████| 391/391 [00:23<00:00, 16.34it/s, batch_id=390, loss=0.8403]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 63 - Accuracy: 33648/50000 (67.30%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 63 - Loss: 0.7440, Accuracy: 7463/10000 (74.63%)\n",
      "Epoch 64: 100%|██████████| 391/391 [00:23<00:00, 16.38it/s, batch_id=390, loss=1.1019]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 64 - Accuracy: 33695/50000 (67.39%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 64 - Loss: 0.7423, Accuracy: 7463/10000 (74.63%)\n",
      "Epoch 65: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=1.0604]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 65 - Accuracy: 33582/50000 (67.16%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 65 - Loss: 0.7448, Accuracy: 7471/10000 (74.71%)\n",
      "Epoch 66: 100%|██████████| 391/391 [00:23<00:00, 16.37it/s, batch_id=390, loss=1.0330]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 66 - Accuracy: 33553/50000 (67.11%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 66 - Loss: 0.7436, Accuracy: 7472/10000 (74.72%)\n",
      "Epoch 67: 100%|██████████| 391/391 [00:23<00:00, 16.37it/s, batch_id=390, loss=0.9749]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 67 - Accuracy: 33590/50000 (67.18%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 67 - Loss: 0.7424, Accuracy: 7480/10000 (74.80%)\n",
      "Epoch 68: 100%|██████████| 391/391 [00:23<00:00, 16.37it/s, batch_id=390, loss=0.9304]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 68 - Accuracy: 33485/50000 (66.97%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 68 - Loss: 0.7445, Accuracy: 7467/10000 (74.67%)\n",
      "Epoch 69: 100%|██████████| 391/391 [00:23<00:00, 16.37it/s, batch_id=390, loss=0.9996]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 69 - Accuracy: 33544/50000 (67.09%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 69 - Loss: 0.7444, Accuracy: 7465/10000 (74.65%)\n",
      "Epoch 70: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=0.9479]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 70 - Accuracy: 33652/50000 (67.30%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 70 - Loss: 0.7433, Accuracy: 7468/10000 (74.68%)\n",
      "Epoch 71: 100%|██████████| 391/391 [00:23<00:00, 16.37it/s, batch_id=390, loss=0.8951]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 71 - Accuracy: 33407/50000 (66.81%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 71 - Loss: 0.7430, Accuracy: 7465/10000 (74.65%)\n",
      "Epoch 72: 100%|██████████| 391/391 [00:23<00:00, 16.35it/s, batch_id=390, loss=0.8103]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 72 - Accuracy: 33609/50000 (67.22%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 72 - Loss: 0.7428, Accuracy: 7456/10000 (74.56%)\n",
      "Epoch 73: 100%|██████████| 391/391 [00:23<00:00, 16.37it/s, batch_id=390, loss=0.9031]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 73 - Accuracy: 33635/50000 (67.27%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 73 - Loss: 0.7433, Accuracy: 7465/10000 (74.65%)\n",
      "Epoch 74: 100%|██████████| 391/391 [00:23<00:00, 16.38it/s, batch_id=390, loss=1.0297]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 74 - Accuracy: 33706/50000 (67.41%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 74 - Loss: 0.7433, Accuracy: 7463/10000 (74.63%)\n",
      "Epoch 75: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=0.9175]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 75 - Accuracy: 33507/50000 (67.01%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 75 - Loss: 0.7445, Accuracy: 7457/10000 (74.57%)\n",
      "Epoch 76: 100%|██████████| 391/391 [00:23<00:00, 16.41it/s, batch_id=390, loss=1.0238]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 76 - Accuracy: 33448/50000 (66.90%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 76 - Loss: 0.7450, Accuracy: 7454/10000 (74.54%)\n",
      "Epoch 77: 100%|██████████| 391/391 [00:23<00:00, 16.38it/s, batch_id=390, loss=1.1407]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 77 - Accuracy: 33717/50000 (67.43%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 77 - Loss: 0.7438, Accuracy: 7463/10000 (74.63%)\n",
      "Epoch 78: 100%|██████████| 391/391 [00:23<00:00, 16.35it/s, batch_id=390, loss=1.1809]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 78 - Accuracy: 33545/50000 (67.09%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 78 - Loss: 0.7417, Accuracy: 7475/10000 (74.75%)\n",
      "Epoch 79: 100%|██████████| 391/391 [00:23<00:00, 16.35it/s, batch_id=390, loss=0.8257]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 79 - Accuracy: 33553/50000 (67.11%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 79 - Loss: 0.7426, Accuracy: 7463/10000 (74.63%)\n",
      "Epoch 80: 100%|██████████| 391/391 [00:23<00:00, 16.41it/s, batch_id=390, loss=1.0008]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 80 - Accuracy: 33519/50000 (67.04%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 80 - Loss: 0.7407, Accuracy: 7474/10000 (74.74%)\n",
      "Epoch 81: 100%|██████████| 391/391 [00:23<00:00, 16.38it/s, batch_id=390, loss=1.0559]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 81 - Accuracy: 33585/50000 (67.17%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 81 - Loss: 0.7453, Accuracy: 7459/10000 (74.59%)\n",
      "Epoch 82: 100%|██████████| 391/391 [00:23<00:00, 16.38it/s, batch_id=390, loss=0.7666]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 82 - Accuracy: 33592/50000 (67.18%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 82 - Loss: 0.7414, Accuracy: 7465/10000 (74.65%)\n",
      "Epoch 83: 100%|██████████| 391/391 [00:23<00:00, 16.35it/s, batch_id=390, loss=1.1247]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 83 - Accuracy: 33562/50000 (67.12%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 83 - Loss: 0.7445, Accuracy: 7465/10000 (74.65%)\n",
      "Epoch 84: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=0.9127]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 84 - Accuracy: 33641/50000 (67.28%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 84 - Loss: 0.7460, Accuracy: 7465/10000 (74.65%)\n",
      "Epoch 85: 100%|██████████| 391/391 [00:23<00:00, 16.38it/s, batch_id=390, loss=0.9194]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 85 - Accuracy: 33484/50000 (66.97%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 85 - Loss: 0.7419, Accuracy: 7472/10000 (74.72%)\n",
      "Epoch 86: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=0.9619]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 86 - Accuracy: 33695/50000 (67.39%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 86 - Loss: 0.7438, Accuracy: 7475/10000 (74.75%)\n",
      "Epoch 87: 100%|██████████| 391/391 [00:23<00:00, 16.41it/s, batch_id=390, loss=1.1869]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 87 - Accuracy: 33572/50000 (67.14%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 87 - Loss: 0.7445, Accuracy: 7466/10000 (74.66%)\n",
      "Epoch 88: 100%|██████████| 391/391 [00:23<00:00, 16.37it/s, batch_id=390, loss=0.8702]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 88 - Accuracy: 33555/50000 (67.11%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 88 - Loss: 0.7447, Accuracy: 7463/10000 (74.63%)\n",
      "Epoch 89: 100%|██████████| 391/391 [00:23<00:00, 16.38it/s, batch_id=390, loss=0.9597]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 89 - Accuracy: 33631/50000 (67.26%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 89 - Loss: 0.7456, Accuracy: 7450/10000 (74.50%)\n",
      "Epoch 90: 100%|██████████| 391/391 [00:23<00:00, 16.37it/s, batch_id=390, loss=0.9649]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 90 - Accuracy: 33493/50000 (66.99%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 90 - Loss: 0.7456, Accuracy: 7452/10000 (74.52%)\n",
      "Epoch 91: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=0.8907]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 91 - Accuracy: 33752/50000 (67.50%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 91 - Loss: 0.7423, Accuracy: 7474/10000 (74.74%)\n",
      "Epoch 92: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=0.8557]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 92 - Accuracy: 33609/50000 (67.22%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 92 - Loss: 0.7450, Accuracy: 7459/10000 (74.59%)\n",
      "Epoch 93: 100%|██████████| 391/391 [00:23<00:00, 16.39it/s, batch_id=390, loss=0.9100]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 93 - Accuracy: 33565/50000 (67.13%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 93 - Loss: 0.7440, Accuracy: 7468/10000 (74.68%)\n",
      "Epoch 94: 100%|██████████| 391/391 [00:23<00:00, 16.38it/s, batch_id=390, loss=0.8582]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 94 - Accuracy: 33574/50000 (67.15%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 94 - Loss: 0.7437, Accuracy: 7468/10000 (74.68%)\n",
      "Epoch 95: 100%|██████████| 391/391 [00:23<00:00, 16.34it/s, batch_id=390, loss=1.0084]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 95 - Accuracy: 33655/50000 (67.31%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 95 - Loss: 0.7417, Accuracy: 7483/10000 (74.83%)\n",
      "Epoch 96: 100%|██████████| 391/391 [00:23<00:00, 16.35it/s, batch_id=390, loss=0.9986]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 96 - Accuracy: 33498/50000 (67.00%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 96 - Loss: 0.7428, Accuracy: 7471/10000 (74.71%)\n",
      "Epoch 97: 100%|██████████| 391/391 [00:23<00:00, 16.35it/s, batch_id=390, loss=0.7564]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 97 - Accuracy: 33499/50000 (67.00%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 97 - Loss: 0.7469, Accuracy: 7463/10000 (74.63%)\n",
      "Epoch 98: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=0.8961]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 98 - Accuracy: 33751/50000 (67.50%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 98 - Loss: 0.7432, Accuracy: 7468/10000 (74.68%)\n",
      "Epoch 99: 100%|██████████| 391/391 [00:23<00:00, 16.35it/s, batch_id=390, loss=0.9675]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 99 - Accuracy: 33505/50000 (67.01%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 99 - Loss: 0.7444, Accuracy: 7466/10000 (74.66%)\n",
      "Epoch 100: 100%|██████████| 391/391 [00:23<00:00, 16.36it/s, batch_id=390, loss=0.9556]\n",
      "INFO:pytorch_play.trainer:[TRAIN ModelV1] Epoch 100 - Accuracy: 33605/50000 (67.21%)\n",
      "INFO:pytorch_play.trainer:[TEST ModelV1] Epoch 100 - Loss: 0.7431, Accuracy: 7454/10000 (74.54%)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"ALBUMENTATIONS_DISABLE_VERSION_CHECK\"] = \"1\"\n",
    "os.environ[\"NO_ALBUMENTATIONS_UPDATE\"] = \"1\"\n",
    "\n",
    "trainer = Trainer(tConfig)\n",
    "trainer.fit(modelV1, device, train_loader, test_loader, modelV1.name())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-play (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
